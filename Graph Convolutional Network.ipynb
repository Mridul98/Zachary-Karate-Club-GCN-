{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Graph Convolutional Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 1., 1., 1.],\n",
       "        [0., 0., 1., 1.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjacency_matrix = np.matrix('0,1,1,1;0,0,1,1;1,0,0,0;0,0,1,0',dtype=np.float32)\n",
    "adjacency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.,  1., -1.,  0.],\n",
       "        [ 5.,  3.,  2.,  1.],\n",
       "        [ 1.,  0.,  0.,  0.],\n",
       "        [ 1.,  1.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix = np.matrix('0,1,-1,0;5,3,2,1;1,0,0,0;1,1,0,0',dtype = np.float32)\n",
    "feature_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propagation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 7.,  4.,  2.,  1.],\n",
       "        [ 2.,  1.,  0.,  0.],\n",
       "        [ 0.,  1., -1.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_0  = np.dot(adjacency_matrix,feature_matrix)\n",
    "layer_0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Including loops\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1., 1., 1., 1.],\n",
       "        [0., 1., 1., 1.],\n",
       "        [1., 0., 1., 0.],\n",
       "        [0., 0., 1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "identity = np.identity(adjacency_matrix.shape[0])\n",
    "adjacency_matrix += identity\n",
    "adjacency_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4., 3., 2., 2.], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = np.array(np.sum(adjacency_matrix,axis = 1)).T[0]\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4., 0., 0., 0.],\n",
       "       [0., 3., 0., 0.],\n",
       "       [0., 0., 2., 0.],\n",
       "       [0., 0., 0., 2.]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diagonal_mat = np.diag(d)\n",
    "diagonal_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.57735026, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.70710677, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.70710677]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inversed_diagonal_mat = np.linalg.inv(diagonal_mat)\n",
    "inversed_diagonal_mat_half_symm = np.linalg.inv(diagonal_mat**0.5)\n",
    "inversed_diagonal_mat_half_symm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized_adj_mat_half_symm\n",
      "[[0.5        0.5        0.5        0.5       ]\n",
      " [0.         0.57735026 0.57735026 0.57735026]\n",
      " [0.70710677 0.         0.70710677 0.        ]\n",
      " [0.         0.         0.70710677 0.70710677]]\n",
      "normalized_adj_mat_full_sym\n",
      "[[0.25       0.28867513 0.35355338 0.35355338]\n",
      " [0.         0.3333333  0.40824828 0.40824828]\n",
      " [0.35355338 0.         0.49999997 0.        ]\n",
      " [0.         0.         0.49999997 0.49999997]]\n"
     ]
    }
   ],
   "source": [
    "normalized_adj_mat = np.dot(inversed_diagonal_mat,adjacency_matrix)\n",
    "normalized_adj_mat_half_symm = np.dot(inversed_diagonal_mat_half_symm,adjacency_matrix)\n",
    "print(\"normalized_adj_mat_half_symm\")\n",
    "print(normalized_adj_mat_half_symm)\n",
    "print(\"normalized_adj_mat_full_sym\")\n",
    "normalized_adj_mat_full_symm = inversed_diagonal_mat_half_symm*adjacency_matrix*inversed_diagonal_mat_half_symm\n",
    "print(normalized_adj_mat_full_symm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining relu function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(a):\n",
    "    mask = a > 0\n",
    "    return np.multiply(a,mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25      , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.33333334, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.5       , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.5       ]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu(inversed_diagonal_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 4, 2, 0],\n",
       "        [0, 3, 0, 1]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu(np.matrix('-1,4,2,-1;-22,3,-1,1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # PyTorch implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from networkx import read_edgelist, set_node_attributes, to_numpy_matrix\n",
    "from pandas import read_csv, Series\n",
    "from numpy import array\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataSet = namedtuple(\n",
    "    'DataSet',\n",
    "    field_names=['X_train', 'y_train', 'X_test', 'y_test', 'network']\n",
    ")\n",
    "\n",
    "def load_karate_club():\n",
    "    network = read_edgelist(\n",
    "        'karate.edgelist',\n",
    "        nodetype=int)\n",
    "\n",
    "    attributes = read_csv(\n",
    "        'karate.attributes.csv',\n",
    "        index_col=['node'])\n",
    "\n",
    "    for attribute in attributes.columns.values:\n",
    "        set_node_attributes(\n",
    "            network,\n",
    "            values=Series(\n",
    "                attributes[attribute],\n",
    "                index=attributes.index).to_dict(),\n",
    "            name=attribute\n",
    "        )\n",
    "  \n",
    "    X_train,y_train = map(array, zip(*[\n",
    "        ([node], data['role'] == 'Administrator')\n",
    "        for node, data in network.nodes(data=True)\n",
    "        if data['role'] in {'Administrator', 'Instructor'}\n",
    "    ]))\n",
    "  \n",
    "    X_test, y_test = map(array, zip(*[\n",
    "        ([node], data['community'] == 'Administrator')\n",
    "        for node, data in network.nodes(data=True)\n",
    "        if data['role'] == 'Member'\n",
    "    ]))\n",
    " \n",
    "    return DataSet(\n",
    "        X_train, y_train,\n",
    "        X_test, y_test,\n",
    "        network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0.])\n",
      "tensor([[0., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.]], dtype=torch.float64)\n",
      "tensor([ 0, 33], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "zkc = load_karate_club()\n",
    "X_train_flattened = torch.flatten(torch.from_numpy(zkc.X_train))\n",
    "X_test_flattened = torch.flatten(torch.from_numpy(zkc.X_test))\n",
    "y_train = torch.from_numpy(zkc.y_train).to(torch.float)\n",
    "\n",
    "print(y_train)\n",
    "A = to_numpy_matrix(zkc.network)\n",
    "A = torch.from_numpy(np.array(A))\n",
    "print(A)\n",
    "print(X_train_flattened)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpectralRule and LogisticRegressor Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectralRule(nn.Module):\n",
    "    \n",
    "    def __init__(self,A,input_units,output_units,activation = 'tanh'):\n",
    "        \n",
    "        super(SpectralRule,self).__init__()\n",
    "        \n",
    "        self.input_units = input_units\n",
    "        self.output_units = output_units\n",
    "        self.linear_layer = nn.Linear(self.input_units,self.output_units)\n",
    "        nn.init.xavier_normal_(self.linear_layer.weight)\n",
    "        if activation == 'relu':\n",
    "            self.activation = nn.ReLU()\n",
    "        elif activation == 'tanh':\n",
    "            self.activation = nn.Tanh()\n",
    "        else:\n",
    "            self.activation = nn.Identity()\n",
    "        #Created Identity Matrix\n",
    "        I = torch.eye(A.shape[1])\n",
    "       \n",
    "        #Adding self loops to the adjacency matrix\n",
    "        A_hat = A + I\n",
    "        A_hat = A_hat.to(torch.double)\n",
    "       \n",
    "        #Inverse degree Matrix\n",
    "        D = torch.diag(torch.pow(torch.sum(A_hat,dim = 0),-0.5),0)\n",
    "       \n",
    "        #applying spectral rule\n",
    "        self.A_hat = torch.matmul(torch.matmul(D,A_hat),D)\n",
    "        self.A_hat.requires_grad = False\n",
    "       \n",
    "        \n",
    "    def forward(self,X):\n",
    "        \n",
    "        #aggregation\n",
    "        aggregation = torch.matmul(self.A_hat,X)\n",
    "         \n",
    "        #propagation\n",
    "        linear_output = self.linear_layer(aggregation.to(torch.float))\n",
    "      \n",
    "        propagation = self.activation(linear_output)\n",
    "          \n",
    "        return propagation.to(torch.double)\n",
    "\n",
    "class LogisticRegressor(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_units,output_units):\n",
    "        super(LogisticRegressor,self).__init__()\n",
    "        \n",
    "        self.Linear = nn.Linear(input_units,output_units,bias=True)\n",
    "        nn.init.xavier_normal_(self.Linear.weight)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self,X):\n",
    "        linear_output = self.Linear(X.to(torch.float))\n",
    "        return self.sigmoid(linear_output)\n",
    "        \n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "identity = torch.eye(A.shape[1])\n",
    "identity = identity.to(torch.double)\n",
    "identity.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_config = [(4,'tanh'),(2,'tanh')]\n",
    "\n",
    "class FeatureModel(nn.Module):\n",
    "    def __init__(self,A,hidden_layer_config,initial_input_size):\n",
    "        super(FeatureModel,self).__init__()\n",
    "        \n",
    "        self.hidden_layer_config = hidden_layer_config\n",
    "        \n",
    "        self.moduleList = list()\n",
    "        \n",
    "        self.initial_input_size = initial_input_size\n",
    "        \n",
    "        for input_size,activation in hidden_layer_config:\n",
    "            \n",
    "            self.moduleList.append(SpectralRule(A,self.initial_input_size,input_size,activation))\n",
    "            self.initial_input_size = input_size\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.sequentialModule = nn.Sequential(*self.moduleList)\n",
    "      \n",
    "           \n",
    "    def forward(self,X):\n",
    "        output = self.sequentialModule(X)\n",
    "       \n",
    "        return output\n",
    "\n",
    "class ClassifierModel(nn.Module):\n",
    "    def __init__(self,input_size,output_size):\n",
    "        super(ClassifierModel,self).__init__()\n",
    "        self.logisticRegressor = LogisticRegressor(input_units=input_size,output_units= output_size)\n",
    "        \n",
    "    def forward(self,X):\n",
    "        \n",
    "        classified  = self.logisticRegressor(X)\n",
    "        return classified\n",
    "    \n",
    "\n",
    "class HybridModel(nn.Module):\n",
    "    def __init__(self,A,hidden_layer_config,initial_input_size):\n",
    "        super(HybridModel,self).__init__()\n",
    "        self.featureModel = FeatureModel(A,hidden_layer_config,identity.shape[1])\n",
    "        self.featureModelOutputSize = self.featureModel.initial_input_size\n",
    "        self.classifier = ClassifierModel(self.featureModelOutputSize,1)\n",
    "        self.featureModelOutput = None\n",
    "    \n",
    "    def forward(self,X):\n",
    "        \n",
    "        outputFeature = self.featureModel(X)\n",
    "        classified = self.classifier(outputFeature)\n",
    "        self.featureModelOutput = outputFeature\n",
    "        return classified\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identity Matrix as feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HybridModel(A,hidden_layer_config,identity.shape[1])\n",
    "\n",
    "output = model(identity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True, False, False, False,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zkc.y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4753],\n",
       "        [0.4176],\n",
       "        [0.3945],\n",
       "        [0.3683],\n",
       "        [0.3792],\n",
       "        [0.4143],\n",
       "        [0.4157],\n",
       "        [0.3418],\n",
       "        [0.3956],\n",
       "        [0.3766],\n",
       "        [0.3454],\n",
       "        [0.3361],\n",
       "        [0.3584],\n",
       "        [0.3312],\n",
       "        [0.3505],\n",
       "        [0.3426],\n",
       "        [0.4066],\n",
       "        [0.3981],\n",
       "        [0.3325],\n",
       "        [0.4043],\n",
       "        [0.3547],\n",
       "        [0.4955],\n",
       "        [0.4153],\n",
       "        [0.5117],\n",
       "        [0.3800],\n",
       "        [0.3774],\n",
       "        [0.3523],\n",
       "        [0.3846],\n",
       "        [0.3806],\n",
       "        [0.3997],\n",
       "        [0.4172],\n",
       "        [0.3787],\n",
       "        [0.4141],\n",
       "        [0.3475]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(),lr = 0.01,momentum=0.9)\n",
    "featureoutput = None\n",
    "\n",
    "def train(model , epoch , criterion , optimizer , feature):\n",
    "    cumLoss = 0\n",
    "    losses = list()\n",
    "    \n",
    "    for j in range(epoch): \n",
    "        two_loss = 0\n",
    "        for i,node in enumerate(X_train_flattened):\n",
    "           \n",
    "            output = model(feature)[node]\n",
    "            \n",
    "            ground_truth = torch.reshape(y_train[i],output.shape)\n",
    "            \n",
    "            \n",
    "            \n",
    "            optimizer.zero_grad() \n",
    "            \n",
    "            loss = criterion(output,ground_truth)\n",
    "            #\\print(\"loss: \",loss.data)\n",
    "            two_loss += loss.item()\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "        losses.append(two_loss)\n",
    "        cumLoss += two_loss\n",
    "    print('avg loss: ',cumLoss/epoch)\n",
    "    torch.save(model.state_dict(),\"./gcn.pth\")\n",
    "    plt.plot(losses)\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg loss:  0.005785782837687293\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAWT0lEQVR4nO3df5Bd5X3f8ff37moFEmAQWidYEhHM4E40GTuQLcV1m5DGjgVNIJlJG2mS2knsaNqU/nKmLYw7xCX/tE7buLZJsMZx3XgSCHE9joaRh2QMbdKkYJaxTUCgsMYOrMFhASNsZLHa3W//uGd374+zey/S3bl6rt6vmZ17z3Oee85z9ojPPjz3POdEZiJJKl9j2A2QJA2GgS5JI8JAl6QRYaBL0ogw0CVpRIwPa8fbt2/P3bt3D2v3klSkhx9++IXMnKxbN7RA3717N9PT08PavSQVKSL+eq11DrlI0ogw0CVpRBjokjQiegZ6RHwyIp6PiEfXWP9zEfFI9fMXEfHWwTdTktRLPz30TwF711n/NeBHMvMtwK8DBwfQLknS69TzKpfM/NOI2L3O+r9oWXwA2Hn6zZIkvV6DHkN/L/D5tVZGxIGImI6I6bm5uQHvWpLObgML9Ij4UZqB/u/XqpOZBzNzKjOnJidrr4vv6eg3v81//eOjvPCd106xpZI0mgYS6BHxFuATwI2Z+eIgtrmWmee/w0fvm+GlV+c3cjeSVJzTDvSIuBT4LPBPMvOvTr9JvfbXfF3ywRyS1Kbnl6IRcSdwLbA9ImaBXwM2AWTmHcCtwMXAb0UzbRcyc2qjGtyoAt08l6R2/Vzlsr/H+vcB7xtYi3pqJro9dElqV9xMUXvoklSvuECvhnUMdEnqUFygr/TQMdElqVVxgb56lctw2yFJZ5oCA315yMVEl6RW5QV69WoPXZLaFRfojeUxF8fQJalNcYHuGLok1Ssu0BtetihJtYoL9NUxdBNdklqVF+j20CWpVoGB3nz1skVJaldcoK+MoQ+5HZJ0piku0L0fuiTVKy7QvduiJNUrLtC9H7ok1Ssu0FfvtihJalVcoHtzLkmqV1ygO4YuSfWKC/RYGUMfckMk6QxTXqA7sUiSahUb6PbQJaldcYHu/dAlqV5xgW4PXZLq9Qz0iPhkRDwfEY+usT4i4iMRMRMRj0TEVYNv5irvhy5J9frpoX8K2LvO+uuAK6qfA8Bvn36z1ub90CWpXs9Az8w/BV5ap8qNwO9m0wPAhRFxyaAa2Cm826Ik1RrEGPoO4JmW5dmqrEtEHIiI6YiYnpubO6WdedmiJNUbRKBHTVlt2mbmwcycysypycnJU9qZY+iSVG8QgT4L7GpZ3gk8O4Dt1nIMXZLqDSLQDwHvrq52uQY4lpnPDWC7teyhS1K98V4VIuJO4Fpge0TMAr8GbALIzDuAw8D1wAxwHPjFjWpssz3NV3voktSuZ6Bn5v4e6xP45wNrUQ/h/dAlqVaBM0W9H7ok1Sku0L0fuiTVKy7QvR+6JNUrLtBXnylqoktSq+ICHe+2KEm1igv0RjiILkl1igv01ZmiQ22GJJ1xigv0hpctSlKt4gLdJxZJUr3yAh3vhy5JdcoL9KrFDrlIUrvyAr16Nc8lqV1xgb78pah3W5SkdsUFundblKR6xQW6D7iQpHrFBfoyh1wkqV1xgb4y9V+S1Ka4QF+ZWOTMIklqU1ygr4yhD7kdknSmKS7QV2/OZaRLUqvyAt2750pSrQID3bstSlKd4gIdmo+hM84lqV2RgR4RjqFLUociA70RjqFLUqe+Aj0i9kbE0YiYiYiba9ZfGhH3R8SXIuKRiLh+8E1t2R/hAy4kqUPPQI+IMeB24DpgD7A/IvZ0VPsPwN2ZeSWwD/itQTe0vU2QjqJLUpt+euhXAzOZ+VRmzgN3ATd21Enggur9G4BnB9fEbuGQiyR16SfQdwDPtCzPVmWtPgj8fETMAoeBf1G3oYg4EBHTETE9Nzd3Cs1takR42aIkdegn0OvuhtWZpvuBT2XmTuB64NMR0bXtzDyYmVOZOTU5Ofn6W9vSIMfQJaldP4E+C+xqWd5J95DKe4G7ATLz/wHnANsH0cA6zR76Rm1dksrUT6A/BFwREZdFxATNLz0PddR5GvgxgIj4fpqBfupjKr2E93KRpE49Az0zF4CbgHuBx2lezfJYRNwWETdU1X4V+OWI+ApwJ/ALuYGD3N4TXZK6jfdTKTMP0/yys7Xs1pb3R4C3D7Zpawt76JLUpdCZoo6hS1KnIgO9eZWLiS5JrcoM9HDqvyR1KjLQxxreD12SOhUZ6A1vnytJXYoN9MWlYbdCks4sZQa6Qy6S1KXMQI9g0UCXpDZFBvqYV7lIUpciA92ZopLUrchAb0SwZBddktoUGehjDS9blKRORQZ6eNmiJHUpMtCdKSpJ3YoMdGeKSlK3IgM9Ilg0zyWpTZGBPhYOuUhSpyIDvXkvFwNdklqVGehetihJXcoM9MCp/5LUodBAd6aoJHUqMtCdKSpJ3YoMdC9blKRuRQa6ly1KUre+Aj0i9kbE0YiYiYib16jzjyPiSEQ8FhG/P9hmtnOmqCR1G+9VISLGgNuBdwKzwEMRcSgzj7TUuQK4BXh7Zn4rIt64UQ2u9ufNuSSpQz899KuBmcx8KjPngbuAGzvq/DJwe2Z+CyAznx9sM9t5cy5J6tZPoO8AnmlZnq3KWr0ZeHNE/HlEPBARe+s2FBEHImI6Iqbn5uZOrcU4U1SS6vQT6FFT1pmm48AVwLXAfuATEXFh14cyD2bmVGZOTU5Ovt62rnCmqCR16yfQZ4FdLcs7gWdr6vxRZp7MzK8BR2kG/IZoRGCeS1K7fgL9IeCKiLgsIiaAfcChjjqfA34UICK20xyCeWqQDW3VCFg00SWpTc9Az8wF4CbgXuBx4O7MfCwibouIG6pq9wIvRsQR4H7g32bmixvV6DEvW5SkLj0vWwTIzMPA4Y6yW1veJ/D+6mfDRQRLXrYoSW3KnCnawB66JHUoMtCdKSpJ3YoMdGeKSlK3IgPdmaKS1K3IQG9EeNmiJHUoNtB9YpEktSs20O2gS1K7QgPdmaKS1KnIQPeZopLUrchAd6aoJHUrMtCdKSpJ3YoMdGeKSlK3IgM9IlhKJxdJUqsiA30smg9RMs8laVWRgd6oHornpYuStKrMQK8S3XF0SVpVZqA75CJJXQoN9ObrovdzkaQVRQb6mEMuktSlyECPasjF2aKStKrIQB+rhlzsoUvSqiID3atcJKlbkYG+POTideiStKrIQHemqCR16yvQI2JvRByNiJmIuHmdej8TERkRU4NrYjcvW5Skbj0DPSLGgNuB64A9wP6I2FNT73zgXwIPDrqRnRxDl6Ru/fTQrwZmMvOpzJwH7gJurKn368CHgBMDbF8tZ4pKUrd+An0H8EzL8mxVtiIirgR2ZeY9620oIg5ExHRETM/Nzb3uxi5zyEWSuvUT6FFTtpKkEdEAfhP41V4bysyDmTmVmVOTk5P9t7KDM0UlqVs/gT4L7GpZ3gk827J8PvADwP+OiK8D1wCHNvKL0ZWZoga6JK3oJ9AfAq6IiMsiYgLYBxxaXpmZxzJze2buzszdwAPADZk5vSEtZvWyRUdcJGlVz0DPzAXgJuBe4HHg7sx8LCJui4gbNrqBdRpO/ZekLuP9VMrMw8DhjrJb16h77ek3a30rM0XtokvSijJnija8bFGSOhUZ6F62KEndygx0L1uUpC5lBrpXuUhSl0IDvflqD12SVhUZ6CvXodtFl6QVRQa6D7iQpG5FBrqXLUpStyID3TF0SepWZKA7U1SSuhUZ6N4+V5K6FRno41WgLywa6JK0rMhA3zTWbPZJA12SVhQZ6ONjVQ99aWnILZGkM0eRgT5hD12SuhQZ6Ms99JOL9tAlaVmRgb48hr5goEvSijIDvdFs9rxDLpK0oshAX/lS1B66JK0oMtBXL1s00CVpWaGBvvylqEMukrSsyECPCMYbYQ9dkloUGejQHEdf8OZckrSi2EDfNNawhy5JLQx0SRoRfQV6ROyNiKMRMRMRN9esf39EHImIRyLiCxHxfYNvartNY+HdFiWpRc9Aj4gx4HbgOmAPsD8i9nRU+xIwlZlvAT4DfGjQDe003mgwbw9dklb000O/GpjJzKcycx64C7ixtUJm3p+Zx6vFB4Cdg21mN3voktSun0DfATzTsjxbla3lvcDn61ZExIGImI6I6bm5uf5bWcMxdElq10+gR01Zbdc4In4emAJ+o259Zh7MzKnMnJqcnOy/lTUMdElqN95HnVlgV8vyTuDZzkoR8Q7gA8CPZOZrg2ne2s6dGOO7Jxc3ejeSVIx+eugPAVdExGURMQHsAw61VoiIK4GPAzdk5vODb2a3czeNcXzeQJekZT0DPTMXgJuAe4HHgbsz87GIuC0ibqiq/QZwHvCHEfHliDi0xuYG5tyJMb5roEvSin6GXMjMw8DhjrJbW96/Y8Dt6mmLQy6S1KbYmaIOuUhSu3IDfWKMEwa6JK0oN9A3jXH85CKZTi6SJCg40LdMjLG4lE7/l6RKsYF+7kTz+1yvdJGkpmID/fxzmoH+7RMLQ26JJJ0Zig30i7ZMAPCt4/NDbokknRmKDfRtWzcB8NKrBrokQcGBvtxDf/n4ySG3RJLODMUHuj10SWoqNtAvOHcTjXAMXZKWFRvoY41g8vzNPHfsxLCbIklnhGIDHeDSbVt4+qXjvStK0lmg6EDftW0Lswa6JAGFB/ql27bw3CsnnC0qSRQe6HsuuYBMOPLcsWE3RZKGruhA/8FdFwLw5WcMdEkqOtDfeME57Np2Ln8+88KwmyJJQ1d0oAO8a8/38n+ffIFXTjhjVNLZrfhA/6krdzC/uMTvPfD0sJsiSUNVfKD/wI438MNvnuSO//NVvukkI0lnseIDHeCDP7mH+YUlDnx6mmPerEvSWWokAv3yyfP46P4reeK5b/MPP/pn3PfE3/isUUlnnZEIdIB37Pke7jxwDZvGGvzSp6bZ++E/42P3Pcmj3zjGSZ87KuksEP30ZCNiL/DfgTHgE5n5nzrWbwZ+F/gh4EXgZzPz6+ttc2pqKqenp0+x2WubX1jic1/+Bnd+8Wm+9PTLAJyzqcH3X3IBuy/eyqXbtrBr2xa2nzfBxVs3s+28CS7eOsE5m8YG3hZJGrSIeDgzp2rX9Qr0iBgD/gp4JzALPATsz8wjLXV+BXhLZv7TiNgH/HRm/ux6292oQG/1zWMn+OLXX+Irz7zMkWdf4emXjvPsse9Sd8gT4w22ToyxZWKcrZvbXzePN5gYazAx3mBT6+tYdJWNNYKxCBqNYKwBjYj2smo5go660VEXgma9iNX3jQCWy4GIoNGyHqr6HeXVxwiq8ojq81Wdxur22so79r9cp9rcitV9t5ZKGrT1An28j89fDcxk5lPVxu4CbgSOtNS5Efhg9f4zwMciInLIA9nf+4ZzuOGtb+KGt75ppey1hUWee/kEL776Gi9+Z54XX53npVfneeXESY6/tsir8wurr/OLvPid48wvLDG/uMT8whInF5c4uZgrZeqtNeNjpSxqypaXuz9Q+8ejpTRq63X/4anfXvRsZ93+O7bcpdfftvVW9/7s2hVOb7+n/ge5537P0GNad+0G7Xff397F+/7+5etv/BT0E+g7gGdalmeBv7NWncxciIhjwMVA2xTOiDgAHAC49NJLT7HJp2fz+Bi7t29l9/atp72tzGRhKVeCfn5hicVMFpeSpSVW31evre+XMllKqrrZUbdZDkkmJFSvzeWl6u9ke1mzPQnQWd6yHar9Ltdd3X62ba9zn6vrWdn3yu+BrCnrrtjPZ1t7AKtl3Rtur7f2/nu1s3MbdZ9t3X9dO+v07sqsXaHXZ9dbnz1atv5nN26/p7O6V79w/c8OZ7+9jnf7eZvXr3CK+gn0uj8znc3tpw6ZeRA4CM0hlz72fUaLCDaNBZvGRua7ZUkF6yeJZoFdLcs7gWfXqhMR48AbgJcG0UBJUn/6CfSHgCsi4rKImAD2AYc66hwC3lO9/xngvmGPn0vS2abnkEs1Jn4TcC/NyxY/mZmPRcRtwHRmHgJ+B/h0RMzQ7Jnv28hGS5K69TOGTmYeBg53lN3a8v4E8I8G2zRJ0uvht3mSNCIMdEkaEQa6JI0IA12SRkRfN+fakB1HzAF/fYof307HLNSzgMd8dvCYzw6nc8zfl5mTdSuGFuinIyKm17o5zajymM8OHvPZYaOO2SEXSRoRBrokjYhSA/3gsBswBB7z2cFjPjtsyDEXOYYuSepWag9dktTBQJekEVFcoEfE3og4GhEzEXHzsNtzqiJiV0TcHxGPR8RjEfGvqvJtEfEnEfFk9XpRVR4R8ZHquB+JiKtatvWeqv6TEfGetfZ5poiIsYj4UkTcUy1fFhEPVu3/g+o2zUTE5mp5plq/u2Ubt1TlRyPiXcM5kv5ExIUR8ZmIeKI6328b9fMcEf+m+nf9aETcGRHnjNp5johPRsTzEfFoS9nAzmtE/FBE/GX1mY9E9PF8wOajxcr4oXn73q8ClwMTwFeAPcNu1ykeyyXAVdX782k+iHsP8CHg5qr8ZuA/V++vBz5P8+lQ1wAPVuXbgKeq14uq9xcN+/h6HPv7gd8H7qmW7wb2Ve/vAP5Z9f5XgDuq9/uAP6je76nO/WbgsurfxNiwj2ud4/2fwPuq9xPAhaN8nmk+kvJrwLkt5/cXRu08Az8MXAU82lI2sPMKfBF4W/WZzwPX9WzTsH8pr/MX+Dbg3pblW4Bbht2uAR3bHwHvBI4Cl1RllwBHq/cfB/a31D9ard8PfLylvK3emfZD84lXXwD+AXBP9Y/1BWC88xzTvAf/26r341W96DzvrfXOtB/ggircoqN8ZM8zq88Y3ladt3uAd43ieQZ2dwT6QM5rte6JlvK2emv9lDbkUvfA6h1DasvAVP+LeSXwIPA9mfkcQPX6xqraWsde2u/kw8C/A5aq5YuBlzNzoVpubX/bw8eB5YePl3TMlwNzwP+ohpk+ERFbGeHznJnfAP4L8DTwHM3z9jCjfZ6XDeq87qjed5avq7RA7+th1CWJiPOA/wX868x8Zb2qNWW5TvkZJyJ+Ang+Mx9uLa6pmj3WFXPMNHucVwG/nZlXAq/S/F/xtRR/zNW48Y00h0neBGwFrqupOkrnuZfXe4yndOylBXo/D6wuRkRsohnmv5eZn62K/yYiLqnWXwI8X5Wvdewl/U7eDtwQEV8H7qI57PJh4MJoPlwc2tu/1sPHSzrmWWA2Mx+slj9DM+BH+Ty/A/haZs5l5kngs8DfZbTP87JBndfZ6n1n+bpKC/R+HlhdhOob698BHs/M/9ayqvWB2++hOba+XP7u6tvya4Bj1f/S3Qv8eERcVPWMfrwqO+Nk5i2ZuTMzd9M8d/dl5s8B99N8uDh0H3Pdw8cPAfuqqyMuA66g+QXSGSczvwk8ExF/qyr6MeAII3yeaQ61XBMRW6p/58vHPLLnucVAzmu17tsRcU31O3x3y7bWNuwvFU7hS4jraV4R8lXgA8Nuz2kcx9+j+b9QjwBfrn6upzl2+AXgyep1W1U/gNur4/5LYKplW78EzFQ/vzjsY+vz+K9l9SqXy2n+hzoD/CGwuSo/p1qeqdZf3vL5D1S/i6P08e3/kI/1B4Hp6lx/jubVDCN9noH/CDwBPAp8muaVKiN1noE7aX5HcJJmj/q9gzyvwFT1+/sq8DE6vliv+3HqvySNiNKGXCRJazDQJWlEGOiSNCIMdEkaEQa6JI0IA12SRoSBLkkj4v8DFXx2Pf9av1gAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(model,10000,criterion,optimizer,identity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('featureModel.sequentialModule.0.linear_layer.weight',\n",
       "              tensor([[ 0.5463,  0.6542, -0.2333,  0.3842,  0.5791,  0.2090,  0.2434,  0.0127,\n",
       "                       -0.2680,  0.3896,  0.2186,  0.1631,  0.2919, -0.3246, -0.0556, -0.1573,\n",
       "                       -0.4211,  0.3313, -0.3623,  0.1321, -0.0385, -0.0583,  0.1372, -0.5186,\n",
       "                        0.0525, -0.0879, -0.4883,  0.0519, -0.0803, -0.6776,  0.2349, -0.7329,\n",
       "                        0.3391, -1.1530],\n",
       "                      [-0.2196, -0.7535, -0.0713, -0.1234,  0.2665, -0.4115, -0.3841, -0.1055,\n",
       "                       -0.2807, -0.0100,  0.0132, -0.1269,  0.2034, -0.0102,  0.1152, -0.1421,\n",
       "                        0.2147, -0.2716,  0.3841, -0.0570,  0.1178,  0.0865, -0.3124,  0.4006,\n",
       "                       -0.4131,  0.0762, -0.1623,  0.1430, -0.2656,  0.3507, -0.0432,  0.3673,\n",
       "                       -0.2273,  1.2699],\n",
       "                      [ 0.2768,  0.0714, -0.2562, -0.1322,  0.0884, -0.1609,  0.1375, -0.0698,\n",
       "                       -0.1521, -0.3547,  0.5154,  0.0291,  0.2831,  0.0238, -0.2727,  0.0302,\n",
       "                        0.5476,  0.2558,  0.1932, -0.0276, -0.2445,  0.0243,  0.0207,  0.0158,\n",
       "                       -0.3884,  0.2367, -0.3739,  0.1316,  0.1121, -0.0451, -0.0886, -0.3348,\n",
       "                        0.0052, -0.3711],\n",
       "                      [ 0.4199, -0.2152,  0.1796,  0.5250,  0.1277,  0.2841,  0.0693, -0.7398,\n",
       "                        0.3940,  0.2354, -0.0426, -0.4271,  0.3861,  0.0870,  0.5518,  0.1414,\n",
       "                        0.2899,  0.2580,  0.2737,  0.2730,  0.1344,  0.1626, -0.0362, -0.2000,\n",
       "                       -0.2046,  0.0298, -0.2240,  0.3868, -0.2686, -0.2965, -0.0193, -0.4486,\n",
       "                        0.2222, -0.6518]])),\n",
       "             ('featureModel.sequentialModule.0.linear_layer.bias',\n",
       "              tensor([ 0.3527, -0.4041,  0.4439,  0.3083])),\n",
       "             ('featureModel.sequentialModule.1.linear_layer.weight',\n",
       "              tensor([[-1.2540,  1.0454, -0.9941, -1.2652],\n",
       "                      [ 1.8887, -1.5215,  0.3057,  0.3498]])),\n",
       "             ('featureModel.sequentialModule.1.linear_layer.bias',\n",
       "              tensor([ 1.6125, -1.3676])),\n",
       "             ('classifier.logisticRegressor.Linear.weight',\n",
       "              tensor([[-4.2819,  4.4419]])),\n",
       "             ('classifier.logisticRegressor.Linear.bias', tensor([-0.3070]))])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8, 10, 11, 12, 13, 17, 19, 21, 31, 30,  9,\n",
       "        27, 28, 32, 16, 14, 15, 18, 20, 22, 23, 25, 29, 24, 26],\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "after = None\n",
    "def test(features):\n",
    "    \n",
    "    model = HybridModel(A,hidden_layer_config,identity.shape[1])\n",
    "    model.load_state_dict(torch.load(\"./gcn.pth\"))\n",
    "    model.eval()\n",
    "    correct = 0 \n",
    "    masked_output = list()\n",
    "    for i ,node in enumerate(X_test_flattened):\n",
    "        output = model(features)[node]\n",
    "        masked_output.append(output.ge(0.5))\n",
    "    \n",
    "    return masked_output  \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "masked = test(identity)\n",
    "masked = [i.item() for i in masked]\n",
    "masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy  0.625\n",
      "precision  0.7\n",
      "recall  0.4375\n"
     ]
    }
   ],
   "source": [
    "test_gt = torch.from_numpy(zkc.y_test)\n",
    "test_gt = [ i.item() for i in test_gt]\n",
    "test_gt\n",
    "counter = 0\n",
    "tp = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "tn = 0\n",
    "\n",
    "correct = zip(masked,test_gt)\n",
    "for (masked,gt) in list(correct):\n",
    "    if masked == gt and masked == True:\n",
    "        tp += 1\n",
    "    if masked == gt and masked == False:\n",
    "        tn += 1\n",
    "    if masked == False and gt == True:\n",
    "        fn += 1\n",
    "    if masked == True and gt == False:\n",
    "        fp += 1\n",
    "accuracy = (tp + tn) / (tp+fp+fn+tn)\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "print('accuracy ',accuracy)\n",
    "print('precision ',precision)\n",
    "print('recall ',recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
